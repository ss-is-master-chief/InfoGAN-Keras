{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoGAN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "uuATdd27CM9K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, concatenate\n",
        "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LAsA_Sg_Kvq4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "num_classes = 10\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "latent_dim = 72"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iuVVuVZdCoMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_disk_and_q_net(img_shape=img_shape, num_classes=num_classes):\n",
        "\n",
        "  img = Input(shape=img_shape)\n",
        "\n",
        "  # Shared layers between discriminator and recognition network\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Conv2D(512, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Flatten())\n",
        "\n",
        "  img_embedding = model(img)\n",
        "\n",
        "  # Discriminator\n",
        "  validity = Dense(1, activation='sigmoid')(img_embedding)\n",
        "\n",
        "  # Recognition\n",
        "  q_net = Dense(128, activation='relu')(img_embedding)\n",
        "  label = Dense(num_classes, activation='softmax')(q_net)\n",
        "\n",
        "  # Return discriminator and recognition network\n",
        "  return Model(img, validity), Model(img, label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YKLuWaMiCVgi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(latent_dim=latent_dim, channels=channels):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
        "  model.add(Reshape((7, 7, 128)))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(Conv2D(channels, kernel_size=3, padding='same'))\n",
        "  model.add(Activation(\"tanh\"))\n",
        "\n",
        "  gen_input = Input(shape=(latent_dim,))\n",
        "  img = model(gen_input)\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return Model(gen_input, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4ZWTOxGCwsO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mutual_info_loss(c, c_given_x):\n",
        "  \"\"\"The mutual information metric we aim to minimize\"\"\"\n",
        "  eps = 1e-8\n",
        "  conditional_entropy = K.mean(- K.sum(K.log(c_given_x + eps) * c, axis=1))\n",
        "  entropy = K.mean(- K.sum(K.log(c + eps) * c, axis=1))\n",
        "\n",
        "  return conditional_entropy + entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVwjlD5dCz7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_generator_input(batch_size, num_classes=num_classes):\n",
        "  # Generator inputs\n",
        "  sampled_noise = np.random.normal(0, 1, (batch_size, 62))\n",
        "  sampled_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "  sampled_labels = to_categorical(sampled_labels, num_classes=num_classes)\n",
        "\n",
        "  return sampled_noise, sampled_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f2AdeALhC2v6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "  # Load the dataset\n",
        "  (X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "  # Rescale -1 to 1\n",
        "  X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "  X_train = np.expand_dims(X_train, axis=3)\n",
        "  y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "  # Adversarial ground truths\n",
        "  valid = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    # ---------------------\n",
        "    #  Train Discriminator\n",
        "    # ---------------------\n",
        "\n",
        "    # Select a random half batch of images\n",
        "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "    imgs = X_train[idx]\n",
        "\n",
        "    # Sample noise and categorical labels\n",
        "    sampled_noise, sampled_labels = sample_generator_input(batch_size)\n",
        "    gen_input = np.concatenate((sampled_noise, sampled_labels), axis=1)\n",
        "\n",
        "    # Generate a half batch of new images\n",
        "    gen_imgs = generator.predict(gen_input)\n",
        "\n",
        "    # Train on real and generated data\n",
        "    d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "    # Avg. loss\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # ---------------------\n",
        "    #  Train Generator and Q-network\n",
        "    # ---------------------\n",
        "\n",
        "    g_loss = combined.train_on_batch(gen_input, [valid, sampled_labels])\n",
        "\n",
        "    # If at save interval => save generated image samples\n",
        "    if epoch % sample_interval == 0:\n",
        "        sample_images(epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZWnki3OCC93N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_images(epoch, num_classes=num_classes):\n",
        "  r, c = 10, 10\n",
        "\n",
        "  fig, axs = plt.subplots(r, c)\n",
        "  for i in range(c):\n",
        "      sampled_noise, _ = sample_generator_input(c)\n",
        "      label = to_categorical(np.full(fill_value=i, shape=(r,1)), num_classes=num_classes)\n",
        "      gen_input = np.concatenate((sampled_noise, label), axis=1)\n",
        "      gen_imgs = generator.predict(gen_input)\n",
        "      gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "      for j in range(r):\n",
        "          axs[j,i].imshow(gen_imgs[j,:,:,0], cmap='gray')\n",
        "          axs[j,i].axis('off')\n",
        "  fig.savefig(\"%d.png\" % epoch)\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ST_vYNofChiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "outputId": "a819160b-0ab7-4e78-9a4c-a1eee54f6547"
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.0002, 0.5)\n",
        "losses = ['binary_crossentropy',mutual_info_loss]\n",
        "\n",
        "# Build and the discriminator and recognition network\n",
        "discriminator, auxilliary = build_disk_and_q_net()\n",
        "\n",
        "discriminator.compile(loss=['binary_crossentropy'], optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Build and compile the recognition network Q\n",
        "auxilliary.compile(loss=[mutual_info_loss], optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Build the generator\n",
        "generator = build_generator()\n",
        "\n",
        "# The generator takes noise and the target label as input\n",
        "# and generates the corresponding digit of that label\n",
        "gen_input = Input(shape=(latent_dim,))\n",
        "img = generator(gen_input)\n",
        "\n",
        "# For the combined model we will only train the generator\n",
        "discriminator.trainable = False\n",
        "\n",
        "# The discriminator takes generated image as input and determines validity\n",
        "valid = discriminator(img)\n",
        "# The recognition network produces the label\n",
        "target_label = auxilliary(img)\n",
        "\n",
        "# The combined model  (stacked generator and discriminator)\n",
        "combined = Model(gen_input, [valid, target_label])\n",
        "combined.compile(loss=losses, optimizer=optimizer)\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_32 (Dense)             (None, 6272)              457856    \n",
            "_________________________________________________________________\n",
            "reshape_8 (Reshape)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_15 (UpSampling (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_16 (UpSampling (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 28, 28, 64)        73792     \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 28, 28, 1)         577       \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 681,089\n",
            "Trainable params: 680,449\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "quKXlngrDEhO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(epochs=4000, batch_size=128, sample_interval=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvWTYqERDAnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_model():\n",
        "\n",
        "  def save(model, model_name):\n",
        "      model_path = \"%s.json\" % model_name\n",
        "      weights_path = \"%s_weights.hdf5\" % model_name\n",
        "      options = {\"file_arch\": model_path,\n",
        "                  \"file_weight\": weights_path}\n",
        "      json_string = model.to_json()\n",
        "      open(options['file_arch'], 'w').write(json_string)\n",
        "      model.save_weights(options['file_weight'])\n",
        "\n",
        "  save(generator, \"generator\")\n",
        "  save(discriminator, \"discriminator\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z1PmizJSYUZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_model()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}